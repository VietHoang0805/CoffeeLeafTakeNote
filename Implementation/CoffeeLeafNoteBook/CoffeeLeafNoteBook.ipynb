{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Library\n",
    "import openpyxl\n",
    "import collections\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import json\n",
    "from shutil import copyfile\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import model.data_loader as data_loader\n",
    "from evaluate import evaluate\n",
    "import loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Diseased Coffee Leaves Using Deep Learning\n",
    "\n",
    "\n",
    "In this project, given a set of images of coffee leaves, this project will explore deep learning algorithms (both fully connected and convolution\n",
    "neural networks) that output the correct labels for the conditions of the coffee leaves. \n",
    "\n",
    "The six conditions are \n",
    "* Healthy (H)\n",
    "* Rust Level 1 (RL1)\n",
    "* Rust Level 2 (RL2)\n",
    "* Rust Level 3 (RL3)\n",
    "* Rust Level 4 (RL4)\n",
    "* Red Spider Mites (RSM)\n",
    "\n",
    "For this project, we explore three different tasks:\n",
    "1) Given the full dataset, classify them into the 6 categories mentioned above.\n",
    "2) Given the full dataset, classify them into 3 categories (H, RL, RSM).\n",
    "3) Given the images from the healthy and rust level categories only, classify them into 5 categories (H, RL1, RL2, RL3, RL4) using a regression-based approach.\n",
    "\n",
    "## Dataset\n",
    "**Robusta dataset**: [Dataset](https://drive.google.com/drive/folders/13fFAQHU_-Ar0zg6RHl1FTLOE3I2QnCWI?usp=sharing)\n",
    "\n",
    "\n",
    "### Setting the Virtual Environment and Installing Requirements\n",
    "Requirements:\n",
    "Run the follow commands:\n",
    "```sh\n",
    "$ pip install -r code/requirements.txt\n",
    "```\n",
    "Processing the Dataset\n",
    "After downloading the annotations and images, they should be placed inside the CoffeeLeafNoteBook directory as follows\n",
    "\n",
    "CoffeeLeafNoteBook/Annotations/{annotation files}\n",
    "CoffeeLeafNoteBook/Photos/{.jpg files}\n",
    "\n",
    "### To process the images for Task 1 above, run the following command:\n",
    "\n",
    "* [Data Processing](#dataprocessing)\n",
    "\n",
    "### To process the images for Task 2 above, run the following command:\n",
    "* [Data Processing For Three Class](#dataprocessingthreeclass)\n",
    "\n",
    "### To process the images for Task 3 above, run the following command:\n",
    "* [Data Processing For RegressionTask](#dataprocessingregression)\n",
    "\n",
    "### Training models\n",
    "To train models, first create a ```params.json``` file inside the ```experiments/{A}/{B}``` directory, where\n",
    "* {A} is either ```six_classes```, ```three_classes```, or ```regression```\n",
    "* {B} is the descriptive name for the experiment model\n",
    "\n",
    "**Then for Task 1 and 2, we use [Training the model](#trainmodel)**\n",
    "\n",
    "**For Task 3, we use the [Train Regression](#trainmodelregression)**\n",
    "\n",
    "### Evaluate on a Saved Model\n",
    "**To evaluate on a saved model, run [Evaluate model](#evaluatef1)**\n",
    "\n",
    "\n",
    "By default, it will evaluate on only the training and validation set.\n",
    "\n",
    "+ To evaluate on the test set, the --testSet True flag must be added.\n",
    "+ To not evaluate on the training and validation set, we can set the --trainAndVal False.\n",
    "+ To evaluate only on the test set, we can set both flags --trainAndVal False --testSet True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing <a class=\"anchor\" id=\"dataprocessing\"></a>\n",
    "This is code for data processing task\n",
    "\n",
    "**Given the full dataset, classify them into the 6 categories mentioned above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_DIM = 720\n",
    "xlsx_path = \"./Annotations/RoCoLe-classes.xlsx\"\n",
    "annotation_json_path = \"./Annotations/RoCoLe-json.json\"\n",
    "photo_path_prefix = \"./Photos/\"\n",
    "binary_path = \"./binary/\"\n",
    "multiclass_path = \"./multiclass/\"\n",
    "\n",
    "binary_classifications = {\n",
    "    \"healthy\": 0,\n",
    "    \"unhealthy\": 1\n",
    "}\n",
    "\n",
    "multiclass_classifications = {\n",
    "    \"healthy\": 0,\n",
    "    \"rust_level_1\": 1,\n",
    "    \"rust_level_2\": 2,\n",
    "    \"rust_level_3\": 3,\n",
    "    \"rust_level_4\": 4,\n",
    "    \"red_spider_mite\": 5\n",
    "}\n",
    "\n",
    "def split_into_train_val_test(dict):\n",
    "    random.seed(230)\n",
    "\n",
    "    test = []\n",
    "    val = []\n",
    "    train = []\n",
    "\n",
    "    for category in dict:\n",
    "        img_names = list(dict[category])\n",
    "        img_names.sort()\n",
    "        random.shuffle(img_names)\n",
    "\n",
    "        test_split = int(0.1 * len(img_names))\n",
    "        val_split = int(.18 * len(img_names))\n",
    "\n",
    "        test_img_names = img_names[:test_split]\n",
    "        val_img_names = img_names[test_split: test_split + val_split]\n",
    "        train_img_names = img_names[test_split + val_split:]\n",
    "\n",
    "        test.extend(test_img_names)\n",
    "        val.extend(val_img_names)\n",
    "        train.extend(train_img_names)\n",
    "\n",
    "    return {\n",
    "        \"test\": set(test),\n",
    "        \"val\": set(val),\n",
    "        \"train\": set(train)\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_binary_and_multiclass_dict_old():\n",
    "    wb_obj = openpyxl.load_workbook(xlsx_path)\n",
    "    sheet_obj = wb_obj.active\n",
    "\n",
    "    binary_dict = collections.defaultdict(set)\n",
    "    multiclass_dict = collections.defaultdict(set)\n",
    "\n",
    "    num_row = sheet_obj.max_row\n",
    "\n",
    "    for i in range(2, num_row + 1):\n",
    "        image_name = sheet_obj.cell(row=i, column=1).value\n",
    "        binary = sheet_obj.cell(row=i, column=2).value\n",
    "        multiclass = sheet_obj.cell(row=i, column=3).value\n",
    "\n",
    "        binary_dict[binary].add(image_name)\n",
    "        multiclass_dict[multiclass].add(image_name)\n",
    "\n",
    "    return binary_dict, multiclass_dict\n",
    "\n",
    "\n",
    "def generate_train_val_test_split(binary_dict, multiclass_dict):\n",
    "    binary_split = split_into_train_val_test(binary_dict)\n",
    "    multiclass_split = split_into_train_val_test(multiclass_dict)\n",
    "    return binary_split, multiclass_split\n",
    "\n",
    "\n",
    "def get_split(img, split_dict):\n",
    "    if img in split_dict[\"test\"]:\n",
    "        return \"test\"\n",
    "    if img in split_dict[\"val\"]:\n",
    "        return \"val\"\n",
    "    return \"train\"\n",
    "\n",
    "\n",
    "def resize_and_save(filename, output_path, size=IMG_DIM):\n",
    "    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n",
    "    image = Image.open(filename)\n",
    "    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n",
    "    image = image.resize((size, size), Image.BILINEAR)\n",
    "    image.save(output_path)\n",
    "\n",
    "\n",
    "def copy_photo_files_into_directories(classification_dict, new_classification_path, classification_type, split_dict):\n",
    "    binary_or_multi = \"binary\" if \"binary\" in new_classification_path else \"multiclass\"\n",
    "    for (category, images) in classification_dict.items():\n",
    "        num = str(classification_type[category])\n",
    "        for img in images:\n",
    "            split = get_split(img, split_dict)\n",
    "            make_dir(os.path.join(\"just_splitted\", binary_or_multi, split))\n",
    "            new_img_path = os.path.join(\"just_splitted\", binary_or_multi, split, num + \"_\" + img)\n",
    "            resize_and_save(os.path.join(photo_path_prefix, img), new_img_path)\n",
    "            # copyfile(os.path.join(\"just_splitted\", \"cropped\", img), new_img_path)\n",
    "\n",
    "\n",
    "def categorize_train_val_test_split(verbose = False):\n",
    "    (binary_dict, multiclass_dict) = generate_binary_and_multiclass_dict_old()\n",
    "    if verbose:\n",
    "        print(\"Finished categorizing pictures into their respective classes for binary and multiclass classification\")\n",
    "    binary_split, multiclass_split = generate_train_val_test_split(binary_dict, multiclass_dict)\n",
    "    if verbose:\n",
    "        print(\"Finished splitting dataset\")\n",
    "    # copy_photo_files_into_directories(binary_dict, binary_path, binary_classifications, binary_split)\n",
    "    # if verbose:\n",
    "    #     print(\"Finished copying photos into the 'binary' folder\")\n",
    "    copy_photo_files_into_directories(multiclass_dict, multiclass_path, multiclass_classifications, multiclass_split)\n",
    "    if verbose:\n",
    "        print(\"Finished copying photos into the 'multiclass' folder\")\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    path = os.path.abspath(os.path.join(path))\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except Exception as e:\n",
    "            # Raise if directory can't be made, because image cuts won't be saved.\n",
    "            print('Error creating directory')\n",
    "            raise e\n",
    "\n",
    "def generate_binary_and_multiclass_dict(img_dimension = IMG_DIM):\n",
    "    binary_dict = collections.defaultdict(set)\n",
    "    multiclass_dict = collections.defaultdict(set)\n",
    "\n",
    "    make_dir(os.path.join(\"zoom_cropped_and_splitted\", \"cropped\"))\n",
    "    with open(annotation_json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        ct = 0\n",
    "        for pic_annotation in data:\n",
    "            if ct % 25 == 0: print(ct)\n",
    "            leaf_obj = pic_annotation[\"Label\"][\"Leaf\"][0]\n",
    "            geometry = leaf_obj[\"geometry\"]\n",
    "            img_name = pic_annotation[\"External ID\"]\n",
    "\n",
    "            binary_classif = leaf_obj[\"state\"]\n",
    "            multi_classif = pic_annotation[\"Label\"][\"classification\"]\n",
    "            classif_num = multiclass_classifications[multi_classif]\n",
    "\n",
    "            image = Image.open(os.path.join(photo_path_prefix, img_name))\n",
    "            width, height = image.size\n",
    "            midx = int(width/2)\n",
    "            midy = int(height/2)\n",
    "            img_dimension_temp = img_dimension * 2\n",
    "            zoom_cropped_img = image.crop((midx - img_dimension_temp, midy - img_dimension_temp, midx + img_dimension_temp, midy + img_dimension_temp))\n",
    "            zoom_cropped_img_name = str(classif_num) + \"_\" + img_name\n",
    "            zoom_cropped_img.save(os.path.join(\"zoom_cropped_and_splitted\", \"cropped\", zoom_cropped_img_name))\n",
    "            binary_dict[binary_classif].add(zoom_cropped_img_name)\n",
    "            multiclass_dict[multi_classif].add(zoom_cropped_img_name)\n",
    "\n",
    "            # for i in range(len(geometry)):\n",
    "            #     xy = geometry[i]\n",
    "            #\n",
    "            #     x = xy[\"x\"]\n",
    "            #     y = xy[\"y\"]\n",
    "            #     xmin = x - img_dimension\n",
    "            #     xmax = x + img_dimension\n",
    "            #     ymin = y - img_dimension\n",
    "            #     ymax = y + img_dimension\n",
    "            #     if xmin < 0 or ymin < 0 or xmax > width or ymax > height:\n",
    "            #         continue\n",
    "            #\n",
    "            #     new_img = image.crop((xmin, ymin, xmax, ymax))\n",
    "            #     new_img_name = str(classif_num) + \"_\" + \"{}_\".format(i) + img_name\n",
    "            #     new_img.save(os.path.join(\"cropped\", new_img_name))\n",
    "            #\n",
    "            #     binary_dict[binary_classif].add(new_img_name)\n",
    "            #     multiclass_dict[multi_classif].add(new_img_name)\n",
    "            ct += 1\n",
    "\n",
    "    return binary_dict, multiclass_dict\n",
    "\n",
    "def main():\n",
    "    categorize_train_val_test_split(True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing For Three Class <a class=\"anchor\" id=\"dataprocessingthreeclass\"></a>\n",
    "This is code for data processing for three class\n",
    "\n",
    "**Given the full dataset, classify them into 3 categories (H, RL, RSM).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 720\n",
    "xlsx_path = \"./Annotations/RoCoLe-classes.xlsx\"\n",
    "photo_path_prefix = \"./Photos/\"\n",
    "\n",
    "\n",
    "multiclass_classifications = {\n",
    "    \"healthy\": 0,\n",
    "    \"rust_level_1\": 1,\n",
    "    \"rust_level_2\": 1,\n",
    "    \"rust_level_3\": 1,\n",
    "    \"rust_level_4\": 1,\n",
    "    \"red_spider_mite\": 2\n",
    "}\n",
    "\n",
    "def split_into_train_val_test(dict):\n",
    "    random.seed(230)\n",
    "\n",
    "    test = []\n",
    "    val = []\n",
    "    train = []\n",
    "\n",
    "    for category in dict:\n",
    "        img_names = list(dict[category])\n",
    "        img_names.sort()\n",
    "        random.shuffle(img_names)\n",
    "\n",
    "        test_split = int(0.1 * len(img_names))\n",
    "        val_split = int(.18 * len(img_names))\n",
    "\n",
    "        test_img_names = img_names[:test_split]\n",
    "        val_img_names = img_names[test_split: test_split + val_split]\n",
    "        train_img_names = img_names[test_split + val_split:]\n",
    "\n",
    "        test.extend(test_img_names)\n",
    "        val.extend(val_img_names)\n",
    "        train.extend(train_img_names)\n",
    "\n",
    "    return {\n",
    "        \"test\": set(test),\n",
    "        \"val\": set(val),\n",
    "        \"train\": set(train)\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_binary_and_multiclass_dict():\n",
    "    wb_obj = openpyxl.load_workbook(xlsx_path)\n",
    "    sheet_obj = wb_obj.active\n",
    "\n",
    "    multiclass_dict = collections.defaultdict(set)\n",
    "\n",
    "    num_row = sheet_obj.max_row\n",
    "\n",
    "    for i in range(2, num_row + 1):\n",
    "        image_name = sheet_obj.cell(row=i, column=1).value\n",
    "        binary = sheet_obj.cell(row=i, column=2).value\n",
    "        multiclass = sheet_obj.cell(row=i, column=3).value\n",
    "\n",
    "        multiclass_dict[multiclass].add(image_name)\n",
    "\n",
    "    return multiclass_dict\n",
    "\n",
    "\n",
    "def generate_train_val_test_split(multiclass_dict):\n",
    "    multiclass_split = split_into_train_val_test(multiclass_dict)\n",
    "    return multiclass_split\n",
    "\n",
    "\n",
    "def get_split(img, split_dict):\n",
    "    if img in split_dict[\"test\"]:\n",
    "        return \"test\"\n",
    "    if img in split_dict[\"val\"]:\n",
    "        return \"val\"\n",
    "    return \"train\"\n",
    "\n",
    "\n",
    "def resize_and_save(filename, output_path, size=IMG_DIM):\n",
    "    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n",
    "    image = Image.open(filename)\n",
    "    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n",
    "    image = image.resize((size, size), Image.BILINEAR)\n",
    "    image.save(output_path)\n",
    "\n",
    "\n",
    "def copy_photo_files_into_directories(classification_dict, classification_type, split_dict):\n",
    "    for (category, images) in classification_dict.items():\n",
    "        num = str(classification_type[category])\n",
    "        for img in images:\n",
    "            split = get_split(img, split_dict)\n",
    "            make_dir(os.path.join(\"three_classes\", \"multiclass\", split))\n",
    "            new_img_path = os.path.join(\"three_classes\", \"multiclass\", split, num + \"_\" + img)\n",
    "            resize_and_save(os.path.join(photo_path_prefix, img), new_img_path)\n",
    "\n",
    "\n",
    "def categorize_train_val_test_split(verbose = False):\n",
    "    multiclass_dict = generate_binary_and_multiclass_dict()\n",
    "    if verbose:\n",
    "        print(\"Finished categorizing pictures into their respective classes for multiclass classification\")\n",
    "    multiclass_split = generate_train_val_test_split(multiclass_dict)\n",
    "    if verbose:\n",
    "        print(\"Finished splitting dataset\")\n",
    "    copy_photo_files_into_directories(multiclass_dict, multiclass_classifications, multiclass_split)\n",
    "    if verbose:\n",
    "        print(\"Finished copying photos into the 'multiclass' folder\")\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    path = os.path.abspath(os.path.join(path))\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except Exception as e:\n",
    "            # Raise if directory can't be made, because image cuts won't be saved.\n",
    "            print('Error creating directory')\n",
    "            raise e\n",
    "\n",
    "def main():\n",
    "    categorize_train_val_test_split(True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing For Regression Task <a class=\"anchor\" id=\"dataprocessingregression\"></a>\n",
    "This is code for data processing for Regression Task\n",
    "\n",
    "**Given the images from the healthy and rust level categories only, classify them into 5 categories (H, RL1, RL2, RL3, RL4) using a regression-based approach.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 720\n",
    "xlsx_path = \"./Annotations/RoCoLe-classes.xlsx\"\n",
    "photo_path_prefix = \"./Photos/\"\n",
    "\n",
    "\n",
    "multiclass_classifications = {\n",
    "    \"healthy\": 0,\n",
    "    \"rust_level_1\": 1,\n",
    "    \"rust_level_2\": 2,\n",
    "    \"rust_level_3\": 3,\n",
    "    \"rust_level_4\": 4,\n",
    "    \"red_spider_mite\": 5\n",
    "}\n",
    "\n",
    "def split_into_train_val_test(dict):\n",
    "    random.seed(230)\n",
    "\n",
    "    test = []\n",
    "    val = []\n",
    "    train = []\n",
    "\n",
    "    for category in dict:\n",
    "        img_names = list(dict[category])\n",
    "        img_names.sort()\n",
    "        random.shuffle(img_names)\n",
    "\n",
    "        test_split = int(0.1 * len(img_names))\n",
    "        val_split = int(.18 * len(img_names))\n",
    "\n",
    "        test_img_names = img_names[:test_split]\n",
    "        val_img_names = img_names[test_split: test_split + val_split]\n",
    "        train_img_names = img_names[test_split + val_split:]\n",
    "\n",
    "        test.extend(test_img_names)\n",
    "        val.extend(val_img_names)\n",
    "        train.extend(train_img_names)\n",
    "\n",
    "    return {\n",
    "        \"test\": set(test),\n",
    "        \"val\": set(val),\n",
    "        \"train\": set(train)\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_binary_and_multiclass_dict():\n",
    "    wb_obj = openpyxl.load_workbook(xlsx_path)\n",
    "    sheet_obj = wb_obj.active\n",
    "\n",
    "    multiclass_dict = collections.defaultdict(set)\n",
    "\n",
    "    num_row = sheet_obj.max_row\n",
    "\n",
    "    for i in range(2, num_row + 1):\n",
    "        image_name = sheet_obj.cell(row=i, column=1).value\n",
    "        multiclass = sheet_obj.cell(row=i, column=3).value\n",
    "\n",
    "        multiclass_dict[multiclass].add(image_name)\n",
    "\n",
    "    return multiclass_dict\n",
    "\n",
    "\n",
    "def generate_train_val_test_split(multiclass_dict):\n",
    "    multiclass_split = split_into_train_val_test(multiclass_dict)\n",
    "    return multiclass_split\n",
    "\n",
    "\n",
    "def get_split(img, split_dict):\n",
    "    if img in split_dict[\"test\"]:\n",
    "        return \"test\"\n",
    "    if img in split_dict[\"val\"]:\n",
    "        return \"val\"\n",
    "    return \"train\"\n",
    "\n",
    "\n",
    "def resize_and_save(filename, output_path, size=IMG_DIM):\n",
    "    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n",
    "    image = Image.open(filename)\n",
    "    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n",
    "    image = image.resize((size, size), Image.BILINEAR)\n",
    "    image.save(output_path)\n",
    "\n",
    "\n",
    "def copy_photo_files_into_directories(classification_dict, classification_type, split_dict):\n",
    "    for (category, images) in classification_dict.items():\n",
    "        num = classification_type[category]\n",
    "        if num == 5: continue\n",
    "        num_str = str(num)\n",
    "        for img in images:\n",
    "            split = get_split(img, split_dict)\n",
    "            make_dir(os.path.join(\"regression\", \"multiclass\", split))\n",
    "            new_img_path = os.path.join(\"regression\", \"multiclass\", split, num_str + \"_\" + img)\n",
    "            resize_and_save(os.path.join(photo_path_prefix, img), new_img_path)\n",
    "\n",
    "\n",
    "def categorize_train_val_test_split(verbose = False):\n",
    "    multiclass_dict = generate_binary_and_multiclass_dict()\n",
    "    if verbose:\n",
    "        print(\"Finished categorizing pictures into their respective classes for multiclass classification\")\n",
    "    multiclass_split = generate_train_val_test_split(multiclass_dict)\n",
    "    if verbose:\n",
    "        print(\"Finished splitting dataset\")\n",
    "    copy_photo_files_into_directories(multiclass_dict, multiclass_classifications, multiclass_split)\n",
    "    if verbose:\n",
    "        print(\"Finished copying photos into the 'multiclass' folder\")\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    path = os.path.abspath(os.path.join(path))\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except Exception as e:\n",
    "            # Raise if directory can't be made, because image cuts won't be saved.\n",
    "            print('Error creating directory')\n",
    "            raise e\n",
    "\n",
    "def main():\n",
    "    categorize_train_val_test_split(True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model For Task 1 and 2 <a class=\"anchor\" id=\"trainmodel\"></a>\n",
    "This is code for training the model for task 1 and task 2\n",
    "\n",
    "+ Task 1: Given the full dataset, classify them into the 6 categories mentioned above.\n",
    "+ Task 2: Given the full dataset, classify them into 3 categories (H, RL, RSM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import model.data_loader as data_loader\n",
    "from evaluate import evaluate\n",
    "import loss_and_metrics\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir', default='experiments/six_classes/example_trans_learning',\n",
    "                    help=\"Directory containing params.json\")\n",
    "parser.add_argument('--restore_file', default=None,\n",
    "                    help=\"Optional, name of the file in --model_dir containing weights to reload before \\\n",
    "                    training\")  # 'best' or 'train'\n",
    "\n",
    "\n",
    "def train(model, optimizer, loss_fn, dataloader, metrics, params):\n",
    "    \"\"\"Train the model on `num_steps` batches\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches training data\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = utils.RunningAverage()\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    with tqdm(total=len(dataloader)) as t:\n",
    "        for i, (train_batch, labels_batch) in enumerate(dataloader):\n",
    "            # move to GPU if available\n",
    "            if params.cuda:\n",
    "                train_batch, labels_batch = train_batch.cuda(\n",
    "                    non_blocking=True), labels_batch.cuda(non_blocking=True)\n",
    "            # convert to torch Variables\n",
    "            train_batch, labels_batch = Variable(\n",
    "                train_batch), Variable(labels_batch)\n",
    "\n",
    "            # compute model output and loss\n",
    "            output_batch = model(train_batch)\n",
    "            loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "            # clear previous gradients, compute gradients of all variables wrt loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # performs updates using calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Evaluate summaries only once in a while\n",
    "            if i % params.save_summary_steps == 0:\n",
    "                # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "                output_batch = output_batch.data.cpu().numpy()\n",
    "                labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "                # compute all metrics on this batch\n",
    "                summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                                 for metric in metrics}\n",
    "                summary_batch['loss'] = loss.item()\n",
    "                summ.append(summary_batch)\n",
    "\n",
    "            # update the average loss\n",
    "            loss_avg.update(loss.item())\n",
    "\n",
    "            t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "            t.update()\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric: np.mean([x[metric]\n",
    "                                     for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
    "                                for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, loss_fn, metrics, params, model_dir,\n",
    "                       restore_file=None):\n",
    "    \"\"\"Train the model and evaluate every epoch.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        train_dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches training data\n",
    "        val_dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches validation data\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        model_dir: (string) directory containing config, weights and log\n",
    "        restore_file: (string) optional- name of file to restore from (without its extension .pth.tar)\n",
    "    \"\"\"\n",
    "    # reload weights from restore_file if specified\n",
    "    if restore_file is not None:\n",
    "        restore_path = os.path.join(\n",
    "            args.model_dir, args.restore_file + '.pth.tar')\n",
    "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
    "        utils.load_checkpoint(restore_path, model, optimizer)\n",
    "\n",
    "    best_val_macro_f1 = 0.0\n",
    "\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # Run one epoch\n",
    "        logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
    "\n",
    "        # compute number of batches in one epoch (one full pass over the training set)\n",
    "        train(model, optimizer, loss_fn, train_dataloader, metrics, params)\n",
    "\n",
    "        # Evaluate for one epoch on validation set\n",
    "        val_metrics = evaluate(model, loss_fn, val_dataloader, metrics, params)\n",
    "\n",
    "        val_macro_f1 = val_metrics['macro f1']\n",
    "        is_best = val_macro_f1 >= best_val_macro_f1\n",
    "\n",
    "        # Save weights\n",
    "        utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optim_dict': optimizer.state_dict()},\n",
    "                              is_best=is_best,\n",
    "                              checkpoint=model_dir)\n",
    "\n",
    "        # If best_eval, best_save_path\n",
    "        if is_best:\n",
    "            logging.info(\"- Found new best macro f1\")\n",
    "            best_val_macro_f1 = val_macro_f1\n",
    "\n",
    "            # Save best val metrics in a json file in the model directory\n",
    "            best_json_path = os.path.join(\n",
    "                model_dir, \"metrics_val_best_weights.json\")\n",
    "            utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "        # Save latest val metrics in a json file in the model directory\n",
    "        last_json_path = os.path.join(\n",
    "            model_dir, \"metrics_val_last_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, last_json_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the parameters from json file\n",
    "    args = parser.parse_args()\n",
    "    json_path = os.path.join(args.model_dir, \"params.json\")\n",
    "    assert os.path.isfile(\n",
    "        json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = utils.Params(json_path)\n",
    "\n",
    "    # use GPU if available\n",
    "    params.cuda = torch.cuda.is_available()\n",
    "    data_dir = 'just_splitted/multiclass' if 'six_classes' in args.model_dir else 'three_classes/multiclass'\n",
    "    # Set the random seed for reproducible experiments\n",
    "    torch.manual_seed(230)\n",
    "    if params.cuda:\n",
    "        torch.cuda.manual_seed(230)\n",
    "\n",
    "    # Set the logger\n",
    "    utils.set_logger(os.path.join(args.model_dir, 'train.log'))\n",
    "\n",
    "    # Create the input data pipeline\n",
    "    logging.info(\"Loading the datasets...\")\n",
    "\n",
    "    # fetch dataloaders\n",
    "    dataloaders = data_loader.fetch_dataloader(\n",
    "        ['train', 'val'], data_dir, params)\n",
    "    train_dl = dataloaders['train']\n",
    "    val_dl = dataloaders['val']\n",
    "\n",
    "    logging.info(\"- done.\")\n",
    "\n",
    "    # model selected is based on params.net\n",
    "    model = utils.get_desired_model(params)\n",
    "\n",
    "    w_decay = params.weight_decay if hasattr(params, 'weight_decay') else 0.0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params.learning_rate, weight_decay=w_decay)\n",
    "\n",
    "    # fetch loss function and metrics\n",
    "    loss_fn = loss_and_metrics.loss_fn\n",
    "    metrics = loss_and_metrics.metrics\n",
    "\n",
    "    # Train the model\n",
    "    logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "    train_and_evaluate(model, train_dl, val_dl, optimizer, loss_fn, metrics, params, args.model_dir,\n",
    "                       args.restore_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model For Task 3 <a class=\"anchor\" id=\"trainmodelregression\"></a>\n",
    "This is code training the model for task 3 \n",
    "\n",
    "**Task 3: Given the images from the healthy and rust level categories only, classify them into 5 categories (H, RL1, RL2, RL3, RL4) using a regression-based approach.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import model.regression_adopted_cnn as regression_cnn\n",
    "import model.data_loader as data_loader\n",
    "from evaluate import evaluate\n",
    "import regression_loss_and_metrics\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir',\n",
    "                    help=\"Directory containing params.json\")\n",
    "parser.add_argument('--restore_file', default=None,\n",
    "                    help=\"Optional, name of the file in --model_dir containing weights to reload before \\\n",
    "                    training\")  # 'best' or 'train'\n",
    "\n",
    "def get_desired_model(params):\n",
    "    return regression_cnn.Regression_Adopted_NN(params).cuda() if params.cuda else regression_cnn.Regression_Adopted_NN(params)\n",
    "\n",
    "def train(model, optimizer, loss_fn, dataloader, metrics, params):\n",
    "    \"\"\"Train the model on `num_steps` batches\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches training data\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = utils.RunningAverage()\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    with tqdm(total=len(dataloader)) as t:\n",
    "        for i, (train_batch, labels_batch) in enumerate(dataloader):\n",
    "            # move to GPU if available\n",
    "            if params.cuda:\n",
    "                train_batch, labels_batch = train_batch.cuda(\n",
    "                    non_blocking=True), labels_batch.cuda(non_blocking=True)\n",
    "            # convert to torch Variables\n",
    "            train_batch, labels_batch = Variable(\n",
    "                train_batch), Variable(labels_batch)\n",
    "\n",
    "            # compute model output and loss\n",
    "            output_batch = model(train_batch)\n",
    "            loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "            # clear previous gradients, compute gradients of all variables wrt loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # performs updates using calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Evaluate summaries only once in a while\n",
    "            if i % params.save_summary_steps == 0:\n",
    "                # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "                output_batch = output_batch.data.cpu().numpy()\n",
    "                labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "                # compute all metrics on this batch\n",
    "                summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                                 for metric in metrics}\n",
    "                summary_batch['loss'] = loss.item()\n",
    "                summ.append(summary_batch)\n",
    "\n",
    "            # update the average loss\n",
    "            loss_avg.update(loss.item())\n",
    "\n",
    "            t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "            t.update()\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric: np.mean([x[metric]\n",
    "                                     for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
    "                                for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, loss_fn, metrics, params, model_dir,\n",
    "                       restore_file=None):\n",
    "    \"\"\"Train the model and evaluate every epoch.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        train_dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches training data\n",
    "        val_dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches validation data\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        model_dir: (string) directory containing config, weights and log\n",
    "        restore_file: (string) optional- name of file to restore from (without its extension .pth.tar)\n",
    "    \"\"\"\n",
    "    # reload weights from restore_file if specified\n",
    "    if restore_file is not None:\n",
    "        restore_path = os.path.join(\n",
    "            args.model_dir, args.restore_file + '.pth.tar')\n",
    "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
    "        utils.load_checkpoint(restore_path, model, optimizer)\n",
    "\n",
    "    best_val_macro_f1 = 0.0\n",
    "\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # Run one epoch\n",
    "        logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
    "\n",
    "        # compute number of batches in one epoch (one full pass over the training set)\n",
    "        train(model, optimizer, loss_fn, train_dataloader, metrics, params)\n",
    "\n",
    "        # Evaluate for one epoch on validation set\n",
    "        val_metrics = evaluate(model, loss_fn, val_dataloader, metrics, params)\n",
    "\n",
    "        val_macro_f1 = val_metrics['macro f1']\n",
    "        is_best = val_macro_f1 >= best_val_macro_f1\n",
    "\n",
    "        # Save weights\n",
    "        utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optim_dict': optimizer.state_dict()},\n",
    "                              is_best=is_best,\n",
    "                              checkpoint=model_dir)\n",
    "\n",
    "        # If best_eval, best_save_path\n",
    "        if is_best:\n",
    "            logging.info(\"- Found new best macro f1\")\n",
    "            best_val_macro_f1 = val_macro_f1\n",
    "\n",
    "            # Save best val metrics in a json file in the model directory\n",
    "            best_json_path = os.path.join(\n",
    "                model_dir, \"metrics_val_best_weights.json\")\n",
    "            utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "        # Save latest val metrics in a json file in the model directory\n",
    "        last_json_path = os.path.join(\n",
    "            model_dir, \"metrics_val_last_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, last_json_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the parameters from json file\n",
    "    args = parser.parse_args()\n",
    "    json_path = os.path.join(args.model_dir, \"params.json\")\n",
    "    assert os.path.isfile(\n",
    "        json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = utils.Params(json_path)\n",
    "\n",
    "    # use GPU if available\n",
    "    params.cuda = torch.cuda.is_available()\n",
    "\n",
    "    # Set the random seed for reproducible experiments\n",
    "    torch.manual_seed(230)\n",
    "    if params.cuda:\n",
    "        torch.cuda.manual_seed(230)\n",
    "\n",
    "    # Set the logger\n",
    "    utils.set_logger(os.path.join(args.model_dir, 'train.log'))\n",
    "\n",
    "    # Create the input data pipeline\n",
    "    logging.info(\"Loading the datasets...\")\n",
    "\n",
    "    # fetch dataloaders\n",
    "    data_dir = 'regression/multiclass'\n",
    "    dataloaders = data_loader.fetch_dataloader(\n",
    "        ['train', 'val'], data_dir, params)\n",
    "    train_dl = dataloaders['train']\n",
    "    val_dl = dataloaders['val']\n",
    "\n",
    "    logging.info(\"- done.\")\n",
    "\n",
    "    # model selected is based on params.net\n",
    "    model = get_desired_model(params)\n",
    "\n",
    "    w_decay = params.weight_decay if hasattr(params, 'weight_decay') else 0.0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params.learning_rate, weight_decay=w_decay)\n",
    "\n",
    "    # fetch loss function and metrics\n",
    "    loss_fn = regression_loss_and_metrics.regression_loss_fn\n",
    "    metrics = regression_loss_and_metrics.regression_metrics\n",
    "\n",
    "    # Train the model\n",
    "    logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "    train_and_evaluate(model, train_dl, val_dl, optimizer, loss_fn, metrics, params, args.model_dir,\n",
    "                       args.restore_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluated Model <a class=\"anchor\" id=\"evaluatef1\"></a>\n",
    "This is code evaluated model\n",
    "\n",
    "**Task 3: Given the images from the healthy and rust level categories only, classify them into 5 categories (H, RL1, RL2, RL3, RL4) using a regression-based approach.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluates the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import utils\n",
    "import model.data_loader as data_loader\n",
    "import regression_loss_and_metrics\n",
    "import loss_and_metrics\n",
    "import model.regression_adopted_cnn as regression_cnn\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir',\n",
    "                    help=\"Directory containing params.json\")\n",
    "parser.add_argument('--restore_file', default='best', help=\"name of the file in --model_dir \\\n",
    "                     containing weights to load\")\n",
    "parser.add_argument('--testSet', default='False',\n",
    "                    help=\"Indicate whether we should get the metrics for the test set.\")\n",
    "parser.add_argument('--trainAndVal', default='True',\n",
    "                    help=\"Indicate whether we should get the metrics for the test set.\")\n",
    "\n",
    "\n",
    "def get_model_loss_metrics(args, params):\n",
    "    if 'regression' in args.model_dir:\n",
    "        model = regression_cnn.Regression_Adopted_NN(params).cuda() if params.cuda else regression_cnn.Regression_Adopted_NN(params)\n",
    "        loss_fn = regression_loss_and_metrics.regression_loss_fn\n",
    "        metrics = regression_loss_and_metrics.regression_metrics\n",
    "        return model, loss_fn, metrics\n",
    "    else:\n",
    "        model = utils.get_desired_model(params)\n",
    "        loss_fn = loss_and_metrics.loss_fn\n",
    "        metrics = loss_and_metrics.metrics\n",
    "        return model, loss_fn, metrics\n",
    "\n",
    "\n",
    "def compute_and_save_f1(saved_outputs, saved_labels, file):\n",
    "    conf_matrix, report = utils.f1_metrics(saved_outputs, saved_labels)\n",
    "\n",
    "    text_file = open(file, \"wt\")\n",
    "    text_file.write('Confusion matrix: \\n {}\\n\\n Classification Report: \\n {}'.format(conf_matrix, report))\n",
    "    text_file.close()\n",
    "\n",
    "def process_output(args, output_batch):\n",
    "    if 'regression' not in args.model_dir:\n",
    "        return np.argmax(output_batch, axis=1)\n",
    "    return np.floor(output_batch + 0.5).flatten()\n",
    "\n",
    "\n",
    "def evaluate(model, loss_fn, dataloader, metrics, params, which_set, file, args):\n",
    "    \"\"\"Evaluate the model on `num_steps` batches.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # summary for current eval loop\n",
    "    summ = []\n",
    "\n",
    "    saved_outputs = []\n",
    "    saved_labels = []\n",
    "    # compute metrics over the dataset\n",
    "    for data_batch, labels_batch in dataloader:\n",
    "        # move to GPU if available\n",
    "        if params.cuda:\n",
    "            data_batch, labels_batch = data_batch.cuda(\n",
    "                non_blocking=True), labels_batch.cuda(non_blocking=True)\n",
    "        # fetch the next evaluation batch\n",
    "        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n",
    "\n",
    "        # compute model output\n",
    "        output_batch = model(data_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "        processed_output = process_output(args, output_batch)\n",
    "        saved_outputs.extend(processed_output)\n",
    "        saved_labels.extend(labels_batch)\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        summary_batch['loss'] = loss.item()\n",
    "        summ.append(summary_batch)\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_name = {metric: np.mean([x[metric]\n",
    "                                     for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
    "                                for k, v in metrics_name.items())\n",
    "    logging.info(\"- {} Metrics : \".format(which_set) + metrics_string)\n",
    "\n",
    "    compute_and_save_f1(saved_outputs, saved_labels, file)\n",
    "\n",
    "    return metrics_name\n",
    "\n",
    "\n",
    "def get_data_dir():\n",
    "    if 'regression' in args.model_dir:\n",
    "        return 'regression/multiclass'\n",
    "    if 'six_classes' in args.model_dir:\n",
    "        return 'just_splitted/multiclass'\n",
    "    if 'three_classes' in args.model_dir:\n",
    "        return 'three_classes/multiclass'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "        Evaluate the model on the train, validation, and test set.\n",
    "    \"\"\"\n",
    "    # Load the parameters\n",
    "    args = parser.parse_args()\n",
    "    json_path = os.path.join(args.model_dir, 'params.json')\n",
    "    assert os.path.isfile(\n",
    "        json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = utils.Params(json_path)\n",
    "\n",
    "    # use GPU if available\n",
    "    params.cuda = torch.cuda.is_available()     # use GPU is available\n",
    "\n",
    "    # Set the random seed for reproducible experiments\n",
    "    torch.manual_seed(230)\n",
    "    if params.cuda:\n",
    "        torch.cuda.manual_seed(230)\n",
    "\n",
    "    # Get the logger\n",
    "    utils.set_logger(os.path.join(args.model_dir, 'trainAndValidation.log'))\n",
    "\n",
    "    # Create the input data pipeline\n",
    "    logging.info(\"Creating the dataset...\")\n",
    "\n",
    "    # fetch dataloaders\n",
    "    data_dir = get_data_dir()\n",
    "    dataloaders = data_loader.fetch_dataloader(['train', 'val', 'test'], data_dir, params)\n",
    "    train_dl = dataloaders['train']\n",
    "    val_dl = dataloaders['val']\n",
    "    test_dl = dataloaders['test']\n",
    "\n",
    "    logging.info(\"- done.\")\n",
    "\n",
    "    # Define the model\n",
    "    model, loss_fn, metrics = get_model_loss_metrics(args, params)\n",
    "\n",
    "    logging.info(\"Starting evaluation and calculation of F1 Scores\")\n",
    "\n",
    "    # Reload weights from the saved file\n",
    "    utils.load_checkpoint(os.path.join(\n",
    "        args.model_dir, args.restore_file + '.pth.tar'), model)\n",
    "\n",
    "    # Evaluate Train\n",
    "    if args.trainAndVal == \"True\":\n",
    "        confus_save_path = os.path.join(\n",
    "            args.model_dir, \"confus_f1_train_{}.json\".format(args.restore_file))\n",
    "        train_metrics = evaluate(model, loss_fn, train_dl, metrics, params, 'Train', confus_save_path, args)\n",
    "        save_path = os.path.join(\n",
    "            args.model_dir, \"metrics_train_{}.json\".format(args.restore_file))\n",
    "        utils.save_dict_to_json(train_metrics, save_path)\n",
    "\n",
    "        # Evaluate Validation\n",
    "        confus_save_path = os.path.join(\n",
    "            args.model_dir, \"confus_f1_val_{}.json\".format(args.restore_file))\n",
    "        val_metrics = evaluate(model, loss_fn, val_dl, metrics, params, 'Val', confus_save_path, args)\n",
    "        save_path = os.path.join(\n",
    "            args.model_dir, \"metrics_val_{}.json\".format(args.restore_file))\n",
    "        utils.save_dict_to_json(val_metrics, save_path)\n",
    "\n",
    "    if args.testSet == \"True\":\n",
    "        confus_save_path = os.path.join(\n",
    "            args.model_dir, \"confus_f1_test_{}.json\".format(args.restore_file))\n",
    "        test_metrics = evaluate(model, loss_fn, test_dl, metrics, params, 'Test', confus_save_path, args)\n",
    "        save_path = os.path.join(\n",
    "            args.model_dir, \"metrics_test_{}.json\".format(args.restore_file))\n",
    "        utils.save_dict_to_json(test_metrics, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
